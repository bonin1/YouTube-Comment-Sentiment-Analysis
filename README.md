# YouTube Comment Sentiment Analysis

A comprehensive tool for scraping YouTube comments and analyzing their sentiment using advanced rule-based classification techniques.

## ğŸš€ Features

- **Multi-method Comment Scraping**: Support for both youtube-comment-scraper and Selenium WebDriver
- **Advanced Text Preprocessing**: Stop word removal, tokenization, lemmatization, and emoji handling
- **Sophisticated Rule-based Sentiment Analysis**: Multi-layered classification with positive, negative, and neutral categories
- **Rich Visualizations**: Interactive pie charts, word clouds, and frequency analysis
- **Comprehensive Analytics**: Word frequency analysis per sentiment class
- **Professional Logging**: Detailed logging with multiple levels
- **Error Handling**: Robust error handling and retry mechanisms
- **Configurable Settings**: Easy configuration through environment variables

## ğŸ“‹ Requirements

- Python 3.8+
- Chrome browser (for Selenium option)
- Internet connection for YouTube access

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/YouTube-Comment-Sentiment-Analysis.git
cd YouTube-Comment-Sentiment-Analysis
```

2. Create a virtual environment:
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# or
source venv/bin/activate  # Linux/Mac
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download NLTK data:
```python
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('vader_lexicon')"
```

## ğŸš€ Usage

### Basic Usage

```python
from src.sentiment_analyzer import YouTubeSentimentAnalyzer

# Initialize analyzer
analyzer = YouTubeSentimentAnalyzer()

# Analyze comments from a YouTube video
video_url = "https://www.youtube.com/watch?v=VIDEO_ID"
results = analyzer.analyze_video(video_url, max_comments=500)

# Generate visualizations
analyzer.create_sentiment_pie_chart(results)
analyzer.create_word_frequency_analysis(results)
```

### Advanced Usage

```python
# Custom configuration
analyzer = YouTubeSentimentAnalyzer(
    scraping_method='selenium',  # or 'youtube-comment-scraper'
    max_retries=3,
    timeout=30
)

# Analyze with custom parameters
results = analyzer.analyze_video(
    video_url,
    max_comments=1000,
    include_replies=True,
    filter_spam=True
)

# Export results
analyzer.export_results(results, format='csv')  # or 'json'
```

## ğŸ“Š Output

The tool generates:
- **Sentiment Distribution**: Interactive pie chart showing sentiment percentages
- **Word Clouds**: Visual representation of most frequent words per sentiment
- **Frequency Analysis**: Bar charts of top words for each sentiment category
- **Detailed Reports**: CSV/JSON exports with individual comment analysis

## ğŸ—ï¸ Project Structure

```
YouTube-Comment-Sentiment-Analysis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper.py              # Comment scraping functionality
â”‚   â”œâ”€â”€ preprocessor.py         # Text preprocessing utilities
â”‚   â”œâ”€â”€ sentiment_rules.py      # Rule-based sentiment classification
â”‚   â”œâ”€â”€ visualizer.py          # Data visualization components
â”‚   â”œâ”€â”€ sentiment_analyzer.py   # Main analyzer class
â”‚   â””â”€â”€ utils.py               # Utility functions
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py            # Configuration settings
â”‚   â””â”€â”€ logging_config.py      # Logging configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ outputs/               # Generated reports and visualizations
â”‚   â””â”€â”€ cache/                 # Cached data
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â”œâ”€â”€ test_sentiment_rules.py
â”‚   â””â”€â”€ test_analyzer.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â””â”€â”€ advanced_analysis.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ API.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ main.py
```

## ğŸ”§ Configuration

Create a `.env` file based on `.env.example`:

```env
# Scraping settings
DEFAULT_SCRAPING_METHOD=youtube-comment-scraper
MAX_COMMENTS=500
TIMEOUT=30
MAX_RETRIES=3

# Output settings
OUTPUT_DIR=data/outputs
CACHE_DIR=data/cache

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/sentiment_analysis.log
```

## ğŸ“ˆ Sentiment Classification Rules

The system uses sophisticated rule-based classification:

### Positive Indicators
- Keywords: love, awesome, amazing, great, excellent, fantastic, wonderful, perfect, best, brilliant
- Emojis: ğŸ˜Š, ğŸ˜, ğŸ‘, â¤ï¸, ğŸ”¥, â­, ğŸ‰, ğŸ‘, ğŸ’¯, ğŸ˜„
- Patterns: Multiple exclamation marks, all caps positive words

### Negative Indicators
- Keywords: hate, boring, terrible, awful, worst, bad, horrible, disgusting, stupid, annoying
- Emojis: ğŸ‘, ğŸ˜, ğŸ˜¡, ğŸ’”, ğŸ˜¢, ğŸ¤®, ğŸ˜¤, ğŸ˜ , ğŸ’©, âŒ
- Patterns: Multiple question marks indicating confusion/frustration

### Neutral Indicators
- Informational content
- Questions without emotional context
- Balanced statements

## ğŸ§ª Testing

Run the test suite:

```bash
python -m pytest tests/ -v
```

## ğŸ“ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- NLTK team for natural language processing tools
- Selenium project for web automation
- YouTube for providing accessible comment data
- The open-source community for inspiration and tools

## ğŸ“ Support

If you encounter any issues or have questions, please [create an issue](https://github.com/yourusername/YouTube-Comment-Sentiment-Analysis/issues) on GitHub.